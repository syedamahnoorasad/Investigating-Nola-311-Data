{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: Data Project Proposal and ETL\n",
    "\n",
    "**Course Project Website Draft**\n",
    "\n",
    "## Team\n",
    "Solo project (no partner).\n",
    "\n",
    "## Project Direction (1-3 Candidate Datasets)\n",
    "For this project, I want to build a public, end-to-end walkthrough that starts with data extraction, continues through cleaning and exploratory analysis, and ends with a clear managerial insight. I am currently considering three realistic datasets and will finalize one after deeper quality checks.\n",
    "\n",
    "**Candidate 1: Retail orders and returns data (CSV export format)**  \n",
    "Why it is promising: this type of data usually includes transaction date, product category, quantity, sales amount, and return status. That structure is good for ETL because it requires date parsing, missing value checks, and joining transactions with returns. It is also useful for business decisions around inventory and pricing.  \n",
    "Question to answer: *Which product categories drive the highest revenue after accounting for returns, and how should managers adjust inventory priorities by month?*\n",
    "\n",
    "**Candidate 2: City bike-share trip data (public transportation logs)**  \n",
    "Why it is promising: trip records often include start station, end station, start time, duration, and rider type. This allows time-based demand analysis and station-level congestion patterns. ETL challenges include filtering abnormal trip durations and engineering features like day-of-week and hour-of-day.  \n",
    "Question to answer: *What are the peak demand windows by station cluster, and where should operators rebalance bikes to reduce stockouts?*\n",
    "\n",
    "**Candidate 3: Restaurant inspection records (city open data portal)**  \n",
    "Why it is promising: inspection data includes violation category, score, inspection date, and neighborhood. It supports operational insights for quality management and compliance risk monitoring. ETL involves standardizing violation labels, handling repeated inspections per location, and creating interpretable risk indicators.  \n",
    "Question to answer: *Which violation categories most strongly predict repeat low scores, and where should inspectors focus follow-up visits?*\n",
    "\n",
    "At this stage, Candidate 1 is my likely final choice because the path from raw data to decision is straightforward and aligns with a managerial audience: category performance, return-adjusted revenue, and seasonal planning.\n",
    "\n",
    "## Collaboration Plan\n",
    "Since I am working solo, I will use a structured weekly workflow to maintain accountability: (1) one coding block for extraction and cleaning, (2) one analysis block for charts and metrics, and (3) one documentation block for notebook updates and GitHub commits. I am using Git + GitHub for version control, Jupyter Notebook for analysis, and GitHub Pages for publication. I will commit incremental progress after each major ETL or analysis change and keep the repository history readable with clear commit messages.\n",
    "\n",
    "## ETL Demonstration (Draft)\n",
    "Below is a small synthetic retail sample showing the ETL workflow I plan to apply to the final dataset: parse dates, normalize categories, compute net sales, and create a tidy table suitable for analysis. This is not the final data source, but it demonstrates that the extraction and transformation pipeline works end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract (sample raw data to mimic CSV ingestion)\n",
    "raw_data = [\n",
    "    {'order_id': 1001, 'order_date': '2025-09-01', 'region': 'North', 'product': 'Office-Chair', 'quantity': 2, 'unit_price': 120, 'returned': 0},\n",
    "    {'order_id': 1002, 'order_date': '2025-09-03', 'region': 'South', 'product': 'Office-Desk', 'quantity': 1, 'unit_price': 260, 'returned': 0},\n",
    "    {'order_id': 1003, 'order_date': '2025-09-05', 'region': 'West',  'product': 'Tech-Headset', 'quantity': 3, 'unit_price': 40,  'returned': 1},\n",
    "    {'order_id': 1004, 'order_date': '2025-10-01', 'region': 'North', 'product': 'Office-Chair', 'quantity': 1, 'unit_price': 120, 'returned': 0},\n",
    "    {'order_id': 1005, 'order_date': '2025-10-08', 'region': 'East',  'product': 'Tech-Mouse',   'quantity': 5, 'unit_price': 25,  'returned': 0},\n",
    "    {'order_id': 1006, 'order_date': '2025-11-02', 'region': 'South', 'product': 'Office-Lamp',  'quantity': 4, 'unit_price': 35,  'returned': 0},\n",
    "    {'order_id': 1007, 'order_date': '2025-11-07', 'region': 'West',  'product': 'Tech-Keyboard','quantity': 2, 'unit_price': 60,  'returned': 0},\n",
    "    {'order_id': 1008, 'order_date': '2025-11-09', 'region': 'East',  'product': 'Office-Desk',  'quantity': 1, 'unit_price': 260, 'returned': 1}\n",
    "]\n",
    "raw_df = pd.DataFrame(raw_data)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to tidy format\n",
    "tidy_df = raw_df.copy()\n",
    "tidy_df['order_date'] = pd.to_datetime(tidy_df['order_date'])\n",
    "tidy_df[['category', 'item']] = tidy_df['product'].str.split('-', n=1, expand=True)\n",
    "tidy_df['gross_sales'] = tidy_df['quantity'] * tidy_df['unit_price']\n",
    "tidy_df['net_sales'] = tidy_df['gross_sales'].where(tidy_df['returned'] == 0, 0)\n",
    "tidy_df['month'] = tidy_df['order_date'].dt.to_period('M').astype(str)\n",
    "tidy_df = tidy_df[['order_id', 'order_date', 'month', 'region', 'category', 'item', 'quantity', 'unit_price', 'returned', 'net_sales']]\n",
    "\n",
    "print('Tidy table preview:')\n",
    "tidy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting stat\n",
    "region_sales = tidy_df.groupby('region', as_index=False)['net_sales'].sum().sort_values('net_sales', ascending=False)\n",
    "top_region = region_sales.iloc[0]\n",
    "print(f\"Top region by net sales: {top_region['region']} (${top_region['net_sales']:.2f})\")\n",
    "region_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph: monthly net sales trend\n",
    "monthly = tidy_df.groupby('month', as_index=False)['net_sales'].sum()\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "ax = sns.lineplot(data=monthly, x='month', y='net_sales', marker='o', linewidth=2.5, color='#1f77b4')\n",
    "ax.set_title('Monthly Net Sales (Draft Dataset)')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Net Sales ($)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Notes and Challenges\n",
    "- Product strings had combined information (category + item), so they were split into separate tidy columns.\n",
    "- Return records needed a business rule to avoid overstating revenue; this draft sets returned transactions to zero net sales.\n",
    "- Dates were parsed and standardized to monthly periods for trend analysis.\n",
    "\n",
    "In the final project, I will apply the same workflow to the chosen real dataset, add more robust validation checks, and extend the analysis with deeper comparisons (category-level seasonality, return-rate risk, and operational recommendations)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
